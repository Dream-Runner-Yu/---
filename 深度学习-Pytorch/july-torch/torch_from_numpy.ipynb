{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.7039,  0.7159, -0.8558,  1.2056,  1.9943,  0.3601,  1.8999, -0.4122],\n        [-0.4122,  1.4688,  0.8050, -0.5271, -1.2572,  1.2877, -0.3825,  1.3130]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "x = torch.randn(4,4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1,8)\n",
    "z\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.1595])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "x\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# dir(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.1595])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "x.grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0.15945971012115479"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.7039, -0.4122],\n        [ 0.7159,  1.4688],\n        [-0.8558,  0.8050],\n        [ 1.2056, -0.5271],\n        [ 1.9943, -1.2572],\n        [ 0.3601,  1.2877],\n        [ 1.8999, -0.3825],\n        [-0.4122,  1.3130]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.transpose(1,0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1., 1., 1., 1., 1.])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "a\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 1., 1., 1., 1.], dtype=float32)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "b = torch.from_numpy(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# dir(b)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    y = torch.ones_like(x,device=device)\n",
    "    x = x.to(device)\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\",torch.double))\n",
    "    y.to(\"cpu\").data.numpy\n",
    "    y.cpu().data.numpy()\n",
    "else:\n",
    "    print(\"False\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    110598.83212851276\n",
      "1    103421.27731818029\n",
      "2    111052.97557799023\n",
      "3    114460.48868692169\n",
      "4    114587.37565457495\n",
      "5    101063.35135368857\n",
      "6    82199.59207084303\n",
      "7    60147.13262567447\n",
      "8    43722.10196876158\n",
      "9    31757.14369461876\n",
      "10    24685.552281638273\n",
      "11    20112.144792350962\n",
      "12    17234.827347441817\n",
      "13    15275.770427447638\n",
      "14    13866.52183897293\n",
      "15    12663.621506661333\n",
      "16    11734.328840211505\n",
      "17    10836.424883344904\n",
      "18    10117.638273358403\n",
      "19    9422.658859502613\n"
     ]
    }
   ],
   "source": [
    "# 模型cuda\n",
    "# model = model.cuda()\n",
    "# numpy 实现两层神经网络\n",
    "\"\"\"\n",
    "h = w1 *  x + b1\n",
    "a = max(0,h)\n",
    "y_hat = w2 * a +  b2\n",
    "numpy 实现前项传播\n",
    "loss  实现反向传播\n",
    "\"\"\"\n",
    "#\n",
    "import numpy as np\n",
    "N, D_in, H, D_out = 64,1000,100,10\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "w1 = np.random.randn(D_in,H)\n",
    "w2 = np.random.randn(H,D_out)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "for t in range(20):\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h,0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "\n",
    "    #compute loss\n",
    "    loss = np.sqrt((y_pred-y)**2).sum()\n",
    "    print(t,\"  \",loss)\n",
    "\n",
    "    # bp\n",
    "    # compute grad\n",
    "    grad_y_pred = 2.0 * ( y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h<0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "\n",
    "    # 更新权重\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# h = x.dot(w1)\n",
    "# h_relu = np.maximum(h,0)\n",
    "# y_pred = h_relu.dot(w2)\n",
    "# y_pred - y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    104631.9609375\n",
      "1    98196.2578125\n",
      "2    96037.1875\n",
      "3    92723.34375\n",
      "4    86135.625\n",
      "5    74664.828125\n",
      "6    62014.515625\n",
      "7    49469.94140625\n",
      "8    39304.8515625\n",
      "9    31815.8203125\n",
      "10    25909.787109375\n",
      "11    22173.203125\n",
      "12    19067.80078125\n",
      "13    16953.587890625\n",
      "14    15268.1376953125\n",
      "15    13934.2861328125\n",
      "16    12858.3115234375\n",
      "17    11878.064453125\n",
      "18    11074.08984375\n",
      "19    10309.806640625\n"
     ]
    }
   ],
   "source": [
    "# 手动自己下降\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "N, D_in, H, D_out = 64,1000,100,10\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "w1 = torch.randn(D_in,H)\n",
    "w2 = torch.randn(H,D_out)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "for t in range(20):\n",
    "    h = x.mm(w1)\n",
    "    # min max  控制区间\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "\n",
    "    #compute loss\n",
    "    loss = torch.sqrt((y_pred-y).pow(2)).sum().item()\n",
    "    print(t,\"  \",loss)\n",
    "\n",
    "    # bp\n",
    "    # compute grad\n",
    "    grad_y_pred = 2.0 * ( y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h<0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "\n",
    "    # 更新权重\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(1., requires_grad=True)\n",
    "w = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)\n",
    "\n",
    "y = w*x + b\n",
    "\n",
    "y.backward()\n",
    "w.grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    29708336.0\n",
      "500    0.01877054199576378\n",
      "1000    3.282770558143966e-05\n",
      "1500    8.45683734951308e-06\n",
      "2000    4.567688392853597e-06\n",
      "2500    2.9773877940897364e-06\n",
      "3000    2.2134017854114063e-06\n",
      "3500    1.7076991980502498e-06\n",
      "4000    1.3651498420585995e-06\n",
      "4500    1.1144190921186237e-06\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "N, D_in, H, D_out = 64,1000,100,10\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "w1 = torch.randn(D_in,H, requires_grad=True)\n",
    "w2 = torch.randn(H,D_out, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "for t in range(5000):\n",
    "    # h = x.mm(w1)\n",
    "    # # min max  控制区间\n",
    "    # h_relu = h.clamp(min=0)\n",
    "    # y_pred = h_relu.mm(w2)\n",
    "\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "\n",
    "    #compute loss\n",
    "    loss = (y_pred-y).pow(2).sum()\n",
    "    if t % 500 == 0:\n",
    "        print(t,\"  \",loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    # bp\n",
    "    # compute grad\n",
    "    # grad_y_pred = 2.0 * ( y_pred - y)\n",
    "    # grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    # grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    # grad_h = grad_h_relu.clone()\n",
    "    # grad_h[h<0] = 0\n",
    "    # grad_w1 = x.t().mm(grad_h)\n",
    "\n",
    "    # 更新权重\n",
    "    # w1.data -= learning_rate * grad_w1.data\n",
    "    # w2.data -= learning_rate * grad_w2.data\n",
    "    with torch.no_grad():\n",
    "        w1.data -= learning_rate * w1.grad.data\n",
    "        w2.data -= learning_rate * w2.grad.data\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 4.8906e-05,  3.6955e-06,  1.0848e-05,  2.0280e-05, -1.9133e-05,\n         1.8001e-05, -3.7074e-05,  3.1590e-06, -1.2994e-05,  1.9550e-05],\n       grad_fn=<SelectBackward0>)"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "(y - y_pred)[1]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    32411706.0\n",
      "50    11973.3896484375\n",
      "100    504.5872802734375\n",
      "150    39.74904251098633\n",
      "200    3.8742401599884033\n",
      "250    0.41466742753982544\n",
      "300    0.04683134704828262\n",
      "350    0.005689364392310381\n",
      "400    0.0009358379757031798\n",
      "450    0.0002564187743701041\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "N, D_in, H, D_out = 64,1000,100,10\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# w1 = torch.randn(D_in,H, requires_grad=True)\n",
    "# w2 = torch.randn(H,D_out, requires_grad=True)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in,H,bias=False),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H,D_out,bias=False),\n",
    ")\n",
    "\n",
    "# 初始化\n",
    "torch.nn.init.normal_(model[0].weight)\n",
    "torch.nn.init.normal_(model[2].weight)\n",
    "# model.cuda()\n",
    "\n",
    "# learning_rate = 1e-4\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='sum')\n",
    "\n",
    "\n",
    "for t in range(500):\n",
    "\n",
    "    y_pred = model(x)\n",
    "\n",
    "    #compute loss\n",
    "    # loss = (y_pred-y).pow(2).sum()\n",
    "    loss = loss_fn(y_pred,y)\n",
    "    if t % 50 == 0:\n",
    "        print(t,\"  \",loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     for param in model.parameters():\n",
    "    #         param -= learning_rate * param.grad\n",
    "    # # model.zero_grad()\n",
    "    optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "# model[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    692.6516723632812\n",
      "50    213.892822265625\n",
      "100    54.61441421508789\n",
      "150    9.1212739944458\n",
      "200    0.8840866088867188\n",
      "250    0.05116650462150574\n",
      "300    0.0025561493821442127\n",
      "350    0.00012613499711733311\n",
      "400    5.318761395756155e-06\n",
      "450    1.6408733927164576e-07\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "N, D_in, H, D_out = 64,1000,100,10\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# model = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(D_in,H,bias=False),\n",
    "#     torch.nn.ReLU(),\n",
    "#     torch.nn.Linear(H,D_out,bias=False),\n",
    "# )\n",
    "\n",
    "class TWOLayerNet(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(TWOLayerNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H, bias=False)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out,bias=False)\n",
    "\n",
    "    def forward(self,x):\n",
    "        y_pred = self.linear2(self.linear1(x).clamp(min=0))\n",
    "        return y_pred\n",
    "\n",
    "model = TWOLayerNet(D_in, H, D_out)\n",
    "\n",
    "# 初始化\n",
    "# torch.nn.init.normal_(model[0].weight)\n",
    "# torch.nn.init.normal_(model[2].weight)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='sum')\n",
    "\n",
    "\n",
    "for t in range(500):\n",
    "\n",
    "    y_pred = model(x)\n",
    "\n",
    "    loss = loss_fn(y_pred,y)\n",
    "    if t % 50 == 0:\n",
    "        print(t,\"  \",loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}